{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file handling\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import unidecode\n",
    "import sys\n",
    "\n",
    "# image handling\n",
    "import base64\n",
    "\n",
    "# AI API\n",
    "import anthropic\n",
    "\n",
    "# parsing\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "# tabular data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# date handling\n",
    "import locale\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined functions\n",
    "# Set path for scripts folder\n",
    "path_scripts = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(path_scripts)\n",
    "from src import custom_logging as clogs, config, processing, postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = clogs.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace original path setup with:\n",
    "batch_id = \"01_2025_03\"\n",
    "batch_paths = config.ensure_batch_paths(batch_id)\n",
    "\n",
    "# Use the paths in your code\n",
    "folder_img_path = batch_paths['img']\n",
    "folder_sg_path = batch_paths['sg_excel']\n",
    "folder_output = batch_paths['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 73 entries, 0 to 72\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Número animal  73 non-null     object\n",
      " 1   Fecha Parto    73 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Número animal</th>\n",
       "      <th>Fecha Parto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321/5</td>\n",
       "      <td>1/03/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0836/3</td>\n",
       "      <td>28/03/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Número animal Fecha Parto\n",
       "0         321/5   1/03/2024\n",
       "1        0836/3  28/03/2024"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get configuration\n",
    "paths = config.get_base_paths()\n",
    "patterns = config.get_file_patterns()\n",
    "columns = config.get_column_settings()\n",
    "settings = config.get_data_settings()\n",
    "\n",
    "# Find the file matching the pattern\n",
    "file_path = glob.glob(os.path.join(folder_sg_path, patterns['sg_file']))[0]\n",
    "\n",
    "# Read the matched file\n",
    "data_sg = pd.read_excel(\n",
    "    file_path,\n",
    "    header=settings['excel_settings']['header_row']\n",
    ")\n",
    "\n",
    "# Rename columns using config\n",
    "data_sg = data_sg.rename(\n",
    "    columns=columns['rename_map']\n",
    ").copy()\n",
    "\n",
    "# Select and drop NA using config\n",
    "data_sg = data_sg[columns['sg_columns']].dropna().copy()\n",
    "\n",
    "# Format date using config\n",
    "data_sg[\"Fecha Parto\"] = data_sg[\"Fecha Parto\"].dt.strftime(\n",
    "    settings['date_formats']['output'])\n",
    "data_sg.info()\n",
    "data_sg.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_level = 99.75\n",
    "prompt_input = f\"\"\"Instruction 1: Convert the text in the image to csv.\n",
    "Instruction 2: Employ a strict approach: add 1 asterisk next to the estimated values for those cells whose text-to-digit conversion are below a {conf_level} percent confidence threshold; it does not matter if data is over-flagged.\n",
    "Instruction 3: Include in comments the confidence threshold used.\n",
    "Instruction 4: Do not use outlier-detection as criteria to flag the data.\n",
    "Instruction 5: Make sure to not use outlier-detection as criteria to flag the data.\n",
    "Instruction 6: If headers are present, include them. If no headers are found, do not include any.\n",
    "Instruction 7: Include any comments before returning output. Limit verbosity.\n",
    "Instruction 8: Return output enclosed in brackets to facilitate parsing.\n",
    "Instruction 9: Do not include any additional comments after final output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'Escaner_20250119_1.jpg', 'Escaner_20250119_2.jpg', 'Escaner_20250119_3.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(os.listdir(folder_img_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 12:03:06 - INFO - Processing file: Escaner_20250119_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 12:03:06 - DEBUG - cols_list initialized: []\n",
      "2025-01-24 12:03:30 - INFO - API Comment: Comments:\n",
      "- Using 99.75% confidence threshold for flagging uncertain values with asterisks.\n",
      "- Headers are present and included.\n",
      "- Some entries contain 'x' which likely indicates missing data.\n",
      "- No outlier detection was used for flagging.\n",
      "2025-01-24 12:03:30 - DEBUG - cols_list initialized: ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:03:30 - INFO - Dataframe successfully created\n",
      "2025-01-24 12:03:30 - DEBUG - cols_list at end of iteration: ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:03:30 - DEBUG - data_df columns: ['Número animal', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count']\n",
      "2025-01-24 12:03:30 - DEBUG - data_final columns: ['Número animal', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count', 'Fecha Parto']\n",
      "2025-01-24 12:03:30 - DEBUG -  columns: ['Número animal', 'Fecha Parto', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count']\n",
      "2025-01-24 12:03:30 - DEBUG - ---\n",
      "2025-01-24 12:03:30 - INFO - Processing file: Escaner_20250119_2.jpg\n",
      "2025-01-24 12:03:30 - DEBUG - cols_list initialized: ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:03:54 - INFO - API Comment: Comments: Using a 99.75% confidence threshold for text-to-digit conversion. Asterisks (*) indicate values below this threshold.\n",
      "2025-01-24 12:03:54 - DEBUG - cols_list current (no update): ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:03:54 - INFO - Dataframe successfully created\n",
      "2025-01-24 12:03:54 - DEBUG - cols_list at end of iteration: ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:03:54 - DEBUG - data_df columns: ['Número animal', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count']\n",
      "2025-01-24 12:03:54 - DEBUG - data_final columns: ['Número animal', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count', 'Fecha Parto']\n",
      "2025-01-24 12:03:54 - DEBUG -  columns: ['Número animal', 'Fecha Parto', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count']\n",
      "2025-01-24 12:03:54 - DEBUG - ---\n",
      "2025-01-24 12:03:54 - INFO - Processing file: Escaner_20250119_3.jpg\n",
      "2025-01-24 12:03:54 - DEBUG - cols_list initialized: ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:04:12 - INFO - API Comment: Comments: Using a 99.75% confidence threshold for text-to-digit conversion. Asterisks (*) indicate values below this threshold.\n",
      "2025-01-24 12:04:12 - DEBUG - cols_list current (no update): ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:04:12 - INFO - Dataframe successfully created\n",
      "2025-01-24 12:04:12 - DEBUG - cols_list at end of iteration: ['Número vaca', 'Nombre', 'Becerro', 'Ene. Lunes 13', 'Ene. Martes 14', 'Ene. Miérc. 15', 'Ene. Jueves 16', 'Ene. Vierne 17', 'Ene. Sáb. 18', 'Ene. Dom. 19', '#']\n",
      "2025-01-24 12:04:12 - DEBUG - data_df columns: ['Número animal', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count']\n",
      "2025-01-24 12:04:12 - DEBUG - data_final columns: ['Número animal', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count', 'Fecha Parto']\n",
      "2025-01-24 12:04:12 - DEBUG -  columns: ['Número animal', 'Fecha Parto', 'Fecha 1', 'Kg/Leche', 'Fecha 2', 'Kg/Leche', 'Fecha 3', 'Kg/Leche', 'Fecha 4', 'Kg/Leche', 'Fecha 5', 'Kg/Leche', 'Fecha 6', 'Kg/Leche', 'Fecha 7', 'Kg/Leche', 'flag_count']\n",
      "2025-01-24 12:04:12 - DEBUG - ---\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "cols_list = []\n",
    "year = settings['year']\n",
    "\n",
    "class NoColsError(Exception):\n",
    "    pass\n",
    "\n",
    "for filename in sorted(os.listdir(folder_img_path)):\n",
    "    if filename.endswith(('.jpeg', '.jpg')):\n",
    "        clogs.log_file_processing(logger, filename)\n",
    "        clogs.log_column_status(logger, \"initialized\", cols_list)\n",
    "\n",
    "        image_path = os.path.join(folder_img_path, filename)\n",
    "\n",
    "        try:\n",
    "            result = processing.extract_img2text(image_path, prompt_input)\n",
    "            clogs.log_api_comment(logger, result.content[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue  # Skip to next file if there's an error\n",
    "\n",
    "        data_string = result.content[0].text.split(\"[\")[1].replace(\"]\", \"\")\n",
    "        parsed_data = postprocessing.parse_csv_string(data_string)\n",
    "\n",
    "        if not cols_list:\n",
    "            if any(\"vaca\" in s.lower() for s in parsed_data[0]):\n",
    "                cols_list = parsed_data[0]\n",
    "                clogs.log_column_status(logger, \"initialized\", cols_list)\n",
    "            else:\n",
    "                clogs.log_validation_error(logger, parsed_data[0], \"No 'vaca' found\")\n",
    "                raise NoColsError(\"No columns found: Check image folder\")\n",
    "        else:\n",
    "            if any(\"vaca\" in s.lower()\n",
    "                   for s in parsed_data[0]) and (cols_list != parsed_data[0]):\n",
    "                cols_list = parsed_data[0]\n",
    "                clogs.log_column_status(logger, \"updated\", cols_list)\n",
    "            else:\n",
    "                clogs.log_column_status(logger, \"current (no update)\", cols_list)\n",
    "\n",
    "        # Create the DataFrame\n",
    "        try:\n",
    "            data_df = pd.DataFrame(parsed_data[1:], columns=cols_list)\n",
    "            clogs.log_dataframe_creation(logger, success=True)\n",
    "        except Exception as e:\n",
    "            clogs.log_dataframe_creation(logger, success=False, error=str(e))\n",
    "            clogs.log_column_list(logger, cols_list, \"Current columns\")\n",
    "            \n",
    "            for c in parsed_data[1:]:\n",
    "                if len(c) > len(cols_list):\n",
    "                    logger.error(f\"Row longer than columns: {c}\")\n",
    "                    break\n",
    "            \n",
    "            logger.warning(\"Breaking processing loop due to DataFrame creation error\")\n",
    "            break\n",
    "\n",
    "        clogs.log_column_status(logger, \"at end of iteration\", cols_list)\n",
    "\n",
    "        data_df['flag_count'] = data_df.apply(\n",
    "            lambda row: row.astype(str).str.count('\\*').sum(), axis=1)\n",
    "\n",
    "        col_label_num = 1\n",
    "        for col in data_df.iloc[:, 3:10].columns.tolist():\n",
    "\n",
    "            data_df[col] = data_df[col].astype(str).str.replace(\"-*\", \"\").str.replace(\"-\", \"\")\n",
    "\n",
    "            # Get the index of the specified column\n",
    "            col_index = data_df.columns.get_loc(col)\n",
    "\n",
    "            col_label_str = postprocessing.normalize_month(\n",
    "                postprocessing.normalize_day(col.replace(\".\", \"\")))\n",
    "\n",
    "            # Insert a new column with the column name as the constant value\n",
    "            data_df.insert(col_index, f'Fecha {col_label_num}',\n",
    "                           postprocessing.convert_to_date(\n",
    "                               col_label_str, year = year))\n",
    "            col_label_num += 1\n",
    "            data_df = data_df.rename(columns={col: \"Kg/Leche\"}).copy()\n",
    "\n",
    "        data_df = data_df.drop(\n",
    "            columns=[\"Nombre\", \"Becerro\", \"Fecha PP\", \"#\"],\n",
    "            errors=\"ignore\").copy()\n",
    "\n",
    "        data_df = data_df.rename(columns={\n",
    "            data_df.columns[0]: \"Número animal\"\n",
    "        }).copy()\n",
    "\n",
    "        data_df[\"Número animal\"] = data_df[\"Número animal\"].str.replace(\n",
    "            \"-\", \"/\").copy()\n",
    "        \n",
    "        clogs.log_dataframe_columns(logger, \"data_df\", data_df.columns.tolist())\n",
    "        data_final = data_df.merge(data_sg, on=\"Número animal\", how=\"left\")\n",
    "        clogs.log_dataframe_columns(logger, \"data_final\", data_final.columns.tolist())\n",
    "        data_final[\"Fecha Parto\"] = data_final[\"Fecha Parto\"].fillna(\n",
    "            \"X*\").copy()\n",
    "\n",
    "        # Reorder columns\n",
    "        cols_to_move = [\"Número animal\", \"Fecha Parto\"]\n",
    "        data_final = processing.reorder_columns(data_final, cols_to_move)\n",
    "\n",
    "        clogs.log_column_list(logger, data_final.columns.tolist())\n",
    "        data_list.append(data_final)\n",
    "        clogs.log_process_separator(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(folder_output,\n",
    "                                 f\"leche_{batch_id}.xlsx\")) as writer:\n",
    "    for i, df in enumerate(data_list):\n",
    "        df.to_excel(writer, sheet_name=f'Sheet_{i+1}', index=False)\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(folder_output,\n",
    "                                 f\"leche_{batch_id}_final.xlsx\")) as writer:\n",
    "    for i, df in enumerate(data_list):\n",
    "        df.to_excel(writer, sheet_name=f'Sheet_{i+1}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_scikit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
